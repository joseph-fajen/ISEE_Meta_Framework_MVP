"""
Evaluation and Scoring Module for ISEE Framework

This module provides functions and classes for evaluating and scoring the outputs 
generated by different combinations of models, instructions, and queries.
"""

import re
import json
import statistics
from typing import Dict, Any, List, Callable, Optional, Tuple, Union
from collections import Counter

class ScoringCriterion:
    """Represents a single scoring criterion for evaluating outputs."""
    
    def __init__(
        self, 
        name: str, 
        description: str, 
        weight: float = 1.0,
        scoring_function: Callable[[str], float] = None
    ):
        """Initialize a scoring criterion.
        
        Args:
            name: Name of the criterion.
            description: Description of what the criterion measures.
            weight: Relative importance of this criterion (default: 1.0).
            scoring_function: Function that takes a text and returns a score (0.0-1.0).
        """
        self.name = name
        self.description = description
        self.weight = weight
        self.scoring_function = scoring_function
    
    def score(self, text: str) -> float:
        """Score the given text according to this criterion.
        
        Args:
            text: The text to score.
            
        Returns:
            A score between 0.0 and 1.0.
            
        Raises:
            ValueError: If no scoring function is defined.
        """
        if self.scoring_function is None:
            raise ValueError(f"No scoring function defined for criterion '{self.name}'")
        
        raw_score = self.scoring_function(text)
        
        # Ensure score is within bounds
        return max(0.0, min(1.0, raw_score))
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to a dictionary representation (without the scoring function).
        
        Returns:
            Dictionary representation of the criterion.
        """
        return {
            "name": self.name,
            "description": self.description,
            "weight": self.weight
        }


class ScoringFramework:
    """Framework for scoring outputs against multiple criteria."""
    
    def __init__(self):
        """Initialize an empty scoring framework."""
        self.criteria: Dict[str, ScoringCriterion] = {}
    
    def add_criterion(self, criterion: ScoringCriterion) -> None:
        """Add a criterion to the framework.
        
        Args:
            criterion: The criterion to add.
            
        Raises:
            ValueError: If a criterion with the same name already exists.
        """
        if criterion.name in self.criteria:
            raise ValueError(f"Criterion '{criterion.name}' already exists")
        
        self.criteria[criterion.name] = criterion
    
    def score_text(self, text: str) -> Dict[str, float]:
        """Score a text against all criteria.
        
        Args:
            text: The text to score.
            
        Returns:
            Dictionary mapping criterion names to scores.
        """
        scores = {}
        for name, criterion in self.criteria.items():
            try:
                scores[name] = criterion.score(text)
            except Exception as e:
                print(f"Error scoring criterion '{name}': {str(e)}")
                scores[name] = 0.0
        
        return scores
    
    def calculate_weighted_score(self, scores: Dict[str, float]) -> float:
        """Calculate a weighted overall score based on individual criterion scores.
        
        Args:
            scores: Dictionary mapping criterion names to scores.
            
        Returns:
            Weighted overall score between 0.0 and 1.0.
        """
        if not scores:
            return 0.0
        
        total_weight = 0.0
        weighted_sum = 0.0
        
        for name, score in scores.items():
            if name in self.criteria:
                weight = self.criteria[name].weight
                weighted_sum += score * weight
                total_weight += weight
        
        if total_weight == 0:
            return 0.0
        
        return weighted_sum / total_weight
    
    def get_criterion_weights(self) -> Dict[str, float]:
        """Get the weights of all criteria.
        
        Returns:
            Dictionary mapping criterion names to weights.
        """
        return {name: criterion.weight for name, criterion in self.criteria.items()}
    
    def set_criterion_weights(self, weights: Dict[str, float]) -> None:
        """Set the weights of criteria.
        
        Args:
            weights: Dictionary mapping criterion names to weights.
            
        Raises:
            KeyError: If a criterion in weights does not exist.
        """
        for name, weight in weights.items():
            if name not in self.criteria:
                raise KeyError(f"Criterion '{name}' does not exist")
            
            self.criteria[name].weight = weight


# Default scoring functions

def count_words(text: str) -> int:
    """Count the number of words in a text.
    
    Args:
        text: The text to analyze.
        
    Returns:
        Number of words.
    """
    return len(re.findall(r'\b\w+\b', text))

def count_sentences(text: str) -> int:
    """Count the number of sentences in a text.
    
    Args:
        text: The text to analyze.
        
    Returns:
        Number of sentences.
    """
    return len(re.findall(r'[.!?]+\s+', text)) + (1 if text and not text.endswith(('.', '!', '?', ' ')) else 0)

def novelty_scoring_function(text: str) -> float:
    """Score the novelty of a text based on simple heuristics.
    
    This is a placeholder function. In a real implementation, this would compare
    the text against a corpus of known solutions or use more sophisticated NLP techniques.
    
    Args:
        text: The text to score.
        
    Returns:
        Novelty score between 0.0 and 1.0.
    """
    # Simple heuristics for illustration purposes
    score = 0.0
    
    # Check for phrases that might indicate novel thinking
    novelty_phrases = [
        "new approach", "innovative", "novel", "unique", "original",
        "unlike existing", "breakthrough", "first time", "revolutionary",
        "paradigm shift", "reimagine", "reinvent", "transform"
    ]
    
    text_lower = text.lower()
    count = sum(1 for phrase in novelty_phrases if phrase in text_lower)
    score += min(0.5, count * 0.1)  # Up to 0.5 for novelty phrases
    
    # Check for complex sentence structures as a proxy for sophisticated thinking
    avg_words_per_sentence = count_words(text) / max(1, count_sentences(text))
    if avg_words_per_sentence > 25:
        score += 0.2  # Complex sentence structure
    elif avg_words_per_sentence > 15:
        score += 0.1  # Moderately complex
    
    # Check for presence of concrete examples
    if "for example" in text_lower or "such as" in text_lower or "instance" in text_lower:
        score += 0.2  # Has examples
    
    # Check for comparative language
    if "unlike" in text_lower or "compared to" in text_lower or "in contrast" in text_lower:
        score += 0.1  # Comparative thinking
    
    return min(1.0, score)

def feasibility_scoring_function(text: str) -> float:
    """Score the feasibility of a solution based on simple heuristics.
    
    This is a placeholder function. In a real implementation, this would use
    more sophisticated analysis techniques.
    
    Args:
        text: The text to score.
        
    Returns:
        Feasibility score between 0.0 and 1.0.
    """
    # Simple heuristics for illustration purposes
    score = 0.5  # Start with neutral score
    
    text_lower = text.lower()
    
    # Check for implementation details
    implementation_phrases = [
        "implementation", "steps to", "how to", "process", "procedure",
        "timeline", "roadmap", "plan", "strategy", "approach", "method"
    ]
    count = sum(1 for phrase in implementation_phrases if phrase in text_lower)
    score += min(0.2, count * 0.04)  # Up to 0.2 for implementation details
    
    # Check for consideration of constraints
    constraint_phrases = [
        "constraint", "limitation", "challenge", "obstacle", "barrier",
        "difficulty", "problem", "issue", "concern", "consideration"
    ]
    count = sum(1 for phrase in constraint_phrases if phrase in text_lower)
    score += min(0.15, count * 0.03)  # Up to 0.15 for constraint consideration
    
    # Check for resource considerations
    resource_phrases = [
        "cost", "budget", "resource", "time", "personnel", "staff",
        "expertise", "skill", "technology", "infrastructure", "scalable"
    ]
    count = sum(1 for phrase in resource_phrases if phrase in text_lower)
    score += min(0.15, count * 0.03)  # Up to 0.15 for resource consideration
    
    # Penalize for vague language
    vague_phrases = [
        "somehow", "might", "could", "possibly", "perhaps",
        "may be", "hopefully", "potentially", "in theory"
    ]
    count = sum(1 for phrase in vague_phrases if phrase in text_lower)
    score -= min(0.3, count * 0.06)  # Up to -0.3 for vague language
    
    return max(0.0, min(1.0, score))

def impact_scoring_function(text: str) -> float:
    """Score the potential impact of a solution based on simple heuristics.
    
    This is a placeholder function. In a real implementation, this would use
    more sophisticated analysis techniques.
    
    Args:
        text: The text to score.
        
    Returns:
        Impact score between 0.0 and 1.0.
    """
    # Simple heuristics for illustration purposes
    score = 0.3  # Start with a modest base score
    
    text_lower = text.lower()
    
    # Check for transformative language
    transformative_phrases = [
        "transform", "revolution", "breakthrough", "paradigm shift", "disrupt",
        "game-changer", "significant impact", "major improvement", "substantial"
    ]
    count = sum(1 for phrase in transformative_phrases if phrase in text_lower)
    score += min(0.25, count * 0.05)  # Up to 0.25 for transformative language
    
    # Check for scale language
    scale_phrases = [
        "global", "widespread", "large-scale", "systemic", "industry-wide",
        "cross-sector", "broad impact", "far-reaching", "pervasive"
    ]
    count = sum(1 for phrase in scale_phrases if phrase in text_lower)
    score += min(0.2, count * 0.04)  # Up to 0.2 for scale language
    
    # Check for quantification
    if re.search(r'\d+%', text) or re.search(r'percent', text_lower) or re.search(r'factor of \d+', text_lower):
        score += 0.15  # Quantified impact
    
    # Check for multiple beneficiaries
    beneficiary_phrases = [
        "users", "customers", "stakeholders", "community", "society",
        "people", "businesses", "organizations", "industry", "sector"
    ]
    count = sum(1 for phrase in beneficiary_phrases if phrase in text_lower)
    score += min(0.1, count * 0.02)  # Up to 0.1 for multiple beneficiaries
    
    return min(1.0, score)

def comprehensiveness_scoring_function(text: str) -> float:
    """Score the comprehensiveness of a solution based on simple heuristics.
    
    This is a placeholder function. In a real implementation, this would use
    more sophisticated analysis techniques.
    
    Args:
        text: The text to score.
        
    Returns:
        Comprehensiveness score between 0.0 and 1.0.
    """
    # Simple heuristics for illustration purposes
    score = 0.2  # Start with a low base score
    
    # Check text length as a basic proxy for comprehensiveness
    word_count = count_words(text)
    if word_count > 500:
        score += 0.2  # Substantial length
    elif word_count > 300:
        score += 0.1  # Moderate length
    
    # Check for structured organization
    has_sections = bool(re.search(r'\n\s*\d+[\.\)]\s+', text) or re.search(r'\n\s*[•\-\*]\s+', text))
    if has_sections:
        score += 0.15  # Structured with bullet points or numbered lists
    
    # Check for multiple perspective consideration
    perspective_phrases = [
        "on the other hand", "however", "alternatively", "in contrast",
        "different perspective", "another approach", "others might", "some argue"
    ]
    text_lower = text.lower()
    count = sum(1 for phrase in perspective_phrases if phrase in text_lower)
    score += min(0.15, count * 0.03)  # Up to 0.15 for multiple perspectives
    
    # Check for addressing multiple aspects of the problem
    aspect_indicators = [
        "first", "second", "third", "finally", "moreover", "additionally",
        "furthermore", "also", "another factor", "next", "lastly"
    ]
    count = sum(1 for indicator in aspect_indicators if re.search(r'\b' + indicator + r'\b', text_lower))
    score += min(0.15, count * 0.03)  # Up to 0.15 for multiple aspects
    
    # Check for consideration of the full lifecycle
    lifecycle_phrases = [
        "short-term", "long-term", "initially", "eventually", "over time",
        "implementation", "maintenance", "evaluation", "assessment", "iteration"
    ]
    count = sum(1 for phrase in lifecycle_phrases if phrase in text_lower)
    score += min(0.15, count * 0.03)  # Up to 0.15 for lifecycle consideration
    
    return min(1.0, score)

def specificity_scoring_function(text: str) -> float:
    """Score the specificity of a solution based on simple heuristics.
    
    This is a placeholder function. In a real implementation, this would use
    more sophisticated analysis techniques.
    
    Args:
        text: The text to score.
        
    Returns:
        Specificity score between 0.0 and 1.0.
    """
    # Simple heuristics for illustration purposes
    score = 0.3  # Start with a moderate base score
    
    text_lower = text.lower()
    
    # Check for concrete details
    if re.search(r'\d+', text):  # Contains numbers
        score += 0.15
    
    # Check for specific examples
    example_phrases = [
        "for example", "specifically", "in particular", "such as",
        "for instance", "namely", "to illustrate"
    ]
    count = sum(1 for phrase in example_phrases if phrase in text_lower)
    score += min(0.2, count * 0.05)  # Up to 0.2 for specific examples
    
    # Check for technical or domain-specific terminology
    # This is a very simplified approach - in reality, would need a domain-specific lexicon
    long_words = [word for word in re.findall(r'\b\w+\b', text_lower) if len(word) > 8]
    unique_long_words = set(long_words)
    score += min(0.2, len(unique_long_words) * 0.02)  # Up to 0.2 for technical terms
    
    # Check for precision in language
    precision_phrases = [
        "precisely", "exactly", "specifically", "defined as", "measured by",
        "consists of", "composed of", "characterized by"
    ]
    count = sum(1 for phrase in precision_phrases if phrase in text_lower)
    score += min(0.15, count * 0.03)  # Up to 0.15 for precise language
    
    return min(1.0, score)


# Create default scoring framework
def create_default_framework() -> ScoringFramework:
    """Create a default scoring framework with standard criteria.
    
    Returns:
        A ScoringFramework with default criteria.
    """
    framework = ScoringFramework()
    
    framework.add_criterion(ScoringCriterion(
        name="novelty",
        description="The degree to which the idea presents new and original concepts",
        weight=0.25,
        scoring_function=novelty_scoring_function
    ))
    
    framework.add_criterion(ScoringCriterion(
        name="feasibility",
        description="The practicality and ease of implementation",
        weight=0.20,
        scoring_function=feasibility_scoring_function
    ))
    
    framework.add_criterion(ScoringCriterion(
        name="impact",
        description="The potential magnitude of positive change",
        weight=0.30,
        scoring_function=impact_scoring_function
    ))
    
    framework.add_criterion(ScoringCriterion(
        name="comprehensiveness",
        description="The degree to which the idea addresses multiple aspects of the problem",
        weight=0.15,
        scoring_function=comprehensiveness_scoring_function
    ))
    
    framework.add_criterion(ScoringCriterion(
        name="specificity",
        description="The level of detail and concreteness",
        weight=0.10,
        scoring_function=specificity_scoring_function
    ))
    
    return framework


# Example usage
if __name__ == "__main__":
    # Create a default scoring framework
    framework = create_default_framework()
    
    # Example text to score
    example_text = """
    A revolutionary approach to urban transportation would combine autonomous electric shuttles with dynamic routing algorithms. 
    Unlike traditional fixed-route buses, these shuttles would continuously optimize their routes based on real-time demand patterns.
    
    Implementation would involve:
    1. Deploying fleets of 8-12 passenger electric shuttles across urban areas
    2. Creating a mobile app for users to request pickups and indicate destinations
    3. Developing algorithms that continuously optimize routes to minimize wait times and maximize efficiency
    4. Integrating with existing public transit systems to provide last-mile connectivity
    
    This system could reduce urban traffic by up to 30% while decreasing transit times by 25% for the average commuter. The initial cost would be approximately $2-3 million per fleet of 10 vehicles, but operational costs would be 40% lower than traditional bus systems due to electrification and reduced labor costs.
    
    For economically disadvantaged communities, subsidized access could be provided through income-qualified fare reductions. The system would substantially improve mobility for residents without cars, connecting them more efficiently to employment centers, educational institutions, and essential services.
    """
    
    # Score the text
    scores = framework.score_text(example_text)
    weighted_score = framework.calculate_weighted_score(scores)
    
    # Print the results
    print("Scoring Results:")
    print("-" * 50)
    for criterion, score in scores.items():
        weight = framework.criteria[criterion].weight
        weighted = score * weight
        print(f"{criterion.capitalize()}: {score:.2f} (weight: {weight:.2f}, weighted: {weighted:.2f})")
    
    print("-" * 50)
    print(f"Overall Score: {weighted_score:.2f}")
